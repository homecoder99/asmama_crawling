#!/usr/bin/env python3
"""
í¬ë¡¤ë§ ê²°ê³¼ ë°ì´í„° ë¶„ì„ í”Œë ˆì´ê·¸ë¼ìš´ë“œ.

Excel íŒŒì¼ì´ë‚˜ JSON íŒŒì¼ì—ì„œ í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ë¡œë“œí•˜ì—¬ í†µê³„ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python playground/analyze_data.py --input=data/asmama_products.xlsx
    python playground/analyze_data.py --input=playground/results/*.json --format=json
"""

import sys
import argparse
import json
from pathlib import Path
from typing import List, Dict, Any
import glob

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False

from crawler.utils import setup_logger, parse_price

logger = setup_logger(__name__)


class DataAnalyzer:
    """í¬ë¡¤ë§ ë°ì´í„° ë¶„ì„ê¸°."""
    
    def __init__(self):
        """ë¶„ì„ê¸° ì´ˆê¸°í™”."""
        self.data: List[Dict[str, Any]] = []
    
    def load_excel(self, file_path: str) -> bool:
        """
        Excel íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•œë‹¤.
        
        Args:
            file_path: Excel íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if not PANDAS_AVAILABLE:
            print("âŒ pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install pandasë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return False
        
        try:
            df = pd.read_excel(file_path)
            
            # JSON ë¬¸ìì—´ ì»¬ëŸ¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            for col in df.columns:
                if col in ['options', 'image_urls']:
                    df[col] = df[col].apply(
                        lambda x: json.loads(x) if isinstance(x, str) and x.startswith('[') else x
                    )
            
            self.data = df.to_dict('records')
            print(f"âœ… Excel ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data)}ê°œ í•­ëª©")
            return True
            
        except Exception as e:
            print(f"âŒ Excel íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def load_json_files(self, pattern: str) -> bool:
        """
        JSON íŒŒì¼ë“¤ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•œë‹¤.
        
        Args:
            pattern: íŒŒì¼ íŒ¨í„´ (glob í˜•ì‹)
            
        Returns:
            ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            files = glob.glob(pattern)
            
            if not files:
                print(f"âŒ íŒ¨í„´ì— ë§ëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pattern}")
                return False
            
            all_data = []
            
            for file_path in files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        file_data = json.load(f)
                    
                    if isinstance(file_data, list):
                        all_data.extend(file_data)
                    elif isinstance(file_data, dict):
                        all_data.append(file_data)
                    
                    print(f"ğŸ“„ {Path(file_path).name}: {len(file_data) if isinstance(file_data, list) else 1}ê°œ í•­ëª©")
                    
                except Exception as e:
                    print(f"âš ï¸  {Path(file_path).name} ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            
            self.data = all_data
            print(f"âœ… JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data)}ê°œ í•­ëª©")
            return True
            
        except Exception as e:
            print(f"âŒ JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def basic_statistics(self) -> Dict[str, Any]:
        """
        ê¸°ë³¸ í†µê³„ ì •ë³´ë¥¼ ìƒì„±í•œë‹¤.
        
        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if not self.data:
            return {"error": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        stats = {
            "total_products": len(self.data),
            "columns": set(),
            "branduid_stats": {},
            "name_stats": {},
            "price_stats": {},
            "options_stats": {},
            "images_stats": {}
        }
        
        # ì»¬ëŸ¼ ìˆ˜ì§‘
        for item in self.data:
            stats["columns"].update(item.keys())
        stats["columns"] = list(stats["columns"])
        
        # branduid í†µê³„
        branduid_list = [item.get('branduid') for item in self.data if item.get('branduid')]
        stats["branduid_stats"] = {
            "count": len(branduid_list),
            "unique_count": len(set(branduid_list)),
            "sample": branduid_list[:5]
        }
        
        # ì œí’ˆëª… í†µê³„
        names = [item.get('name') for item in self.data if item.get('name')]
        stats["name_stats"] = {
            "count": len(names),
            "empty_count": len(self.data) - len(names),
            "avg_length": sum(len(name) for name in names) / len(names) if names else 0,
            "sample": names[:3]
        }
        
        # ê°€ê²© í†µê³„
        prices = []
        for item in self.data:
            price = item.get('price')
            if isinstance(price, (int, float)) and price > 0:
                prices.append(price)
            elif isinstance(price, str):
                parsed_price = parse_price(price)
                if parsed_price:
                    prices.append(parsed_price)
        
        if prices:
            stats["price_stats"] = {
                "count": len(prices),
                "min": min(prices),
                "max": max(prices),
                "avg": sum(prices) / len(prices),
                "empty_count": len(self.data) - len(prices)
            }
        
        # ì˜µì…˜ í†µê³„
        options_data = []
        for item in self.data:
            options = item.get('options', [])
            if isinstance(options, list):
                options_data.extend(options)
        
        stats["options_stats"] = {
            "total_options": len(options_data),
            "unique_options": len(set(options_data)),
            "products_with_options": len([item for item in self.data if item.get('options')]),
            "common_options": self._get_most_common(options_data, 5)
        }
        
        # ì´ë¯¸ì§€ í†µê³„
        image_counts = []
        for item in self.data:
            images = item.get('image_urls', [])
            if isinstance(images, list):
                image_counts.append(len(images))
        
        if image_counts:
            stats["images_stats"] = {
                "products_with_images": len([c for c in image_counts if c > 0]),
                "total_images": sum(image_counts),
                "avg_images_per_product": sum(image_counts) / len(image_counts),
                "max_images": max(image_counts),
                "min_images": min(image_counts)
            }
        
        return stats
    
    def _get_most_common(self, items: List[str], limit: int = 5) -> List[tuple]:
        """
        ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” í•­ëª©ë“¤ì„ ë°˜í™˜í•œë‹¤.
        
        Args:
            items: í•­ëª© ë¦¬ìŠ¤íŠ¸
            limit: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜
            
        Returns:
            (í•­ëª©, ê°œìˆ˜) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        from collections import Counter
        counter = Counter(items)
        return counter.most_common(limit)
    
    def quality_analysis(self) -> Dict[str, Any]:
        """
        ë°ì´í„° í’ˆì§ˆ ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.
        
        Returns:
            í’ˆì§ˆ ë¶„ì„ ê²°ê³¼
        """
        if not self.data:
            return {"error": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        quality = {
            "completeness": {},
            "validity": {},
            "consistency": {},
            "issues": []
        }
        
        # ì™„ì„±ë„ ë¶„ì„
        required_fields = ['branduid', 'name', 'price']
        for field in required_fields:
            filled_count = len([item for item in self.data if item.get(field)])
            quality["completeness"][field] = {
                "filled": filled_count,
                "empty": len(self.data) - filled_count,
                "percentage": (filled_count / len(self.data)) * 100
            }
        
        # ìœ íš¨ì„± ë¶„ì„
        # ê°€ê²© ìœ íš¨ì„±
        valid_prices = 0
        for item in self.data:
            price = item.get('price')
            if isinstance(price, (int, float)) and price > 0:
                valid_prices += 1
            elif isinstance(price, str) and parse_price(price):
                valid_prices += 1
        
        quality["validity"]["price"] = {
            "valid": valid_prices,
            "invalid": len(self.data) - valid_prices,
            "percentage": (valid_prices / len(self.data)) * 100
        }
        
        # ì¼ê´€ì„± ë¶„ì„
        # branduid ì¤‘ë³µ ê²€ì‚¬
        branduid_list = [item.get('branduid') for item in self.data if item.get('branduid')]
        duplicates = len(branduid_list) - len(set(branduid_list))
        quality["consistency"]["branduid_duplicates"] = duplicates
        
        # ì´ìŠˆ ë°œê²¬
        if duplicates > 0:
            quality["issues"].append(f"branduid ì¤‘ë³µ: {duplicates}ê°œ")
        
        empty_names = len(self.data) - len([item for item in self.data if item.get('name')])
        if empty_names > 0:
            quality["issues"].append(f"ì œí’ˆëª… ëˆ„ë½: {empty_names}ê°œ")
        
        return quality
    
    def generate_report(self) -> str:
        """
        ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•œë‹¤.
        
        Returns:
            ë¶„ì„ ë³´ê³ ì„œ í…ìŠ¤íŠ¸
        """
        stats = self.basic_statistics()
        quality = self.quality_analysis()
        
        report = []
        report.append("ğŸ“Š í¬ë¡¤ë§ ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ")
        report.append("=" * 50)
        report.append("")
        
        # ê¸°ë³¸ í†µê³„
        report.append("ğŸ“ˆ ê¸°ë³¸ í†µê³„:")
        report.append(f"  ì´ ì œí’ˆ ìˆ˜: {stats.get('total_products', 0):,}ê°œ")
        report.append(f"  ë°ì´í„° ì»¬ëŸ¼: {', '.join(stats.get('columns', []))}")
        report.append("")
        
        # branduid í†µê³„
        if 'branduid_stats' in stats:
            bs = stats['branduid_stats']
            report.append("ğŸ†” Branduid í†µê³„:")
            report.append(f"  ì´ ê°œìˆ˜: {bs.get('count', 0)}ê°œ")
            report.append(f"  ê³ ìœ  ê°œìˆ˜: {bs.get('unique_count', 0)}ê°œ")
            report.append("")
        
        # ì œí’ˆëª… í†µê³„
        if 'name_stats' in stats:
            ns = stats['name_stats']
            report.append("ğŸ“ ì œí’ˆëª… í†µê³„:")
            report.append(f"  ì œí’ˆëª… ìˆìŒ: {ns.get('count', 0)}ê°œ")
            report.append(f"  ì œí’ˆëª… ì—†ìŒ: {ns.get('empty_count', 0)}ê°œ")
            report.append(f"  í‰ê·  ê¸¸ì´: {ns.get('avg_length', 0):.1f}ì")
            report.append("")
        
        # ê°€ê²© í†µê³„
        if 'price_stats' in stats:
            ps = stats['price_stats']
            report.append("ğŸ’° ê°€ê²© í†µê³„:")
            report.append(f"  ê°€ê²© ìˆìŒ: {ps.get('count', 0)}ê°œ")
            report.append(f"  ìµœì €ê°€: {ps.get('min', 0):,}ì›")
            report.append(f"  ìµœê³ ê°€: {ps.get('max', 0):,}ì›")
            report.append(f"  í‰ê· ê°€: {ps.get('avg', 0):,.0f}ì›")
            report.append("")
        
        # ì˜µì…˜ í†µê³„
        if 'options_stats' in stats:
            os = stats['options_stats']
            report.append("ğŸ¨ ì˜µì…˜ í†µê³„:")
            report.append(f"  ì´ ì˜µì…˜ ìˆ˜: {os.get('total_options', 0)}ê°œ")
            report.append(f"  ê³ ìœ  ì˜µì…˜ ìˆ˜: {os.get('unique_options', 0)}ê°œ")
            report.append(f"  ì˜µì…˜ ìˆëŠ” ì œí’ˆ: {os.get('products_with_options', 0)}ê°œ")
            if os.get('common_options'):
                report.append("  ì¸ê¸° ì˜µì…˜:")
                for option, count in os['common_options']:
                    report.append(f"    - {option}: {count}ê°œ")
            report.append("")
        
        # ì´ë¯¸ì§€ í†µê³„
        if 'images_stats' in stats:
            imgs = stats['images_stats']
            report.append("ğŸ–¼ï¸  ì´ë¯¸ì§€ í†µê³„:")
            report.append(f"  ì´ë¯¸ì§€ ìˆëŠ” ì œí’ˆ: {imgs.get('products_with_images', 0)}ê°œ")
            report.append(f"  ì´ ì´ë¯¸ì§€ ìˆ˜: {imgs.get('total_images', 0)}ê°œ")
            report.append(f"  ì œí’ˆë‹¹ í‰ê·  ì´ë¯¸ì§€: {imgs.get('avg_images_per_product', 0):.1f}ê°œ")
            report.append("")
        
        # í’ˆì§ˆ ë¶„ì„
        report.append("ğŸ” ë°ì´í„° í’ˆì§ˆ ë¶„ì„:")
        if 'completeness' in quality:
            for field, comp in quality['completeness'].items():
                report.append(f"  {field} ì™„ì„±ë„: {comp.get('percentage', 0):.1f}% ({comp.get('filled', 0)}/{comp.get('filled', 0) + comp.get('empty', 0)})")
        
        if quality.get('issues'):
            report.append("")
            report.append("âš ï¸  ë°œê²¬ëœ ì´ìŠˆ:")
            for issue in quality['issues']:
                report.append(f"  - {issue}")
        
        return "\n".join(report)


def save_report(report: str, output_file: str = "playground/results/analysis_report.txt"):
    """
    ë¶„ì„ ë³´ê³ ì„œë¥¼ íŒŒì¼ë¡œ ì €ì¥í•œë‹¤.
    
    Args:
        report: ë³´ê³ ì„œ í…ìŠ¤íŠ¸
        output_file: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ğŸ’¾ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {output_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(description="í¬ë¡¤ë§ ë°ì´í„° ë¶„ì„ ë„êµ¬")
    parser.add_argument(
        "--input",
        required=True,
        help="ë¶„ì„í•  ë°ì´í„° íŒŒì¼ (Excel ë˜ëŠ” JSON íŒ¨í„´)"
    )
    parser.add_argument(
        "--format",
        choices=["excel", "json"],
        help="ì…ë ¥ íŒŒì¼ í˜•ì‹ (ìë™ ê°ì§€ë¨)"
    )
    parser.add_argument(
        "--output",
        default="playground/results/analysis_report.txt",
        help="ë³´ê³ ì„œ ì €ì¥ íŒŒì¼"
    )
    parser.add_argument(
        "--detailed",
        action="store_true",
        help="ìƒì„¸ ë¶„ì„ ëª¨ë“œ"
    )
    
    args = parser.parse_args()
    
    print("ğŸ“Š ë°ì´í„° ë¶„ì„ í”Œë ˆì´ê·¸ë¼ìš´ë“œ")
    print("=" * 40)
    
    analyzer = DataAnalyzer()
    
    # íŒŒì¼ í˜•ì‹ ìë™ ê°ì§€
    input_path = args.input
    if args.format == "json" or "*" in input_path or input_path.endswith(".json"):
        success = analyzer.load_json_files(input_path)
    elif args.format == "excel" or input_path.endswith((".xlsx", ".xls")):
        success = analyzer.load_excel(input_path)
    else:
        print("âŒ íŒŒì¼ í˜•ì‹ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. --format ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        sys.exit(1)
    
    if not success:
        sys.exit(1)
    
    # ë¶„ì„ ìˆ˜í–‰
    print("\nğŸ” ë¶„ì„ ìˆ˜í–‰ ì¤‘...")
    report = analyzer.generate_report()
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + report)
    
    # íŒŒì¼ ì €ì¥
    save_report(report, args.output)
    
    if args.detailed:
        print("\nğŸ“‹ ìƒì„¸ í†µê³„ (JSON):")
        stats = analyzer.basic_statistics()
        print(json.dumps(stats, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()