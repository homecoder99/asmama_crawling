"""
Qoo10_ItemInfo Excel íŒŒì¼ì˜ ë°ì´í„°ë¥¼ upload_history í…Œì´ë¸”ë¡œ ì´ì „í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.

ì‚¬ìš©ë²•:
    python scripts/migrate_qoo10_to_upload_history.py --input data/Qoo10_ItemInfo_20251021171235.xlsx --user admin
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from datetime import datetime
import pandas as pd
import psycopg2
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def migrate_to_upload_history(excel_file: str, uploaded_by: str = "admin", skip_rows: int = 2):
    """
    Qoo10_ItemInfo Excel íŒŒì¼ì˜ seller_unique_item_idë¥¼ upload_historyë¡œ ì´ì „í•œë‹¤.

    Args:
        excel_file: Qoo10_ItemInfo Excel íŒŒì¼ ê²½ë¡œ
        uploaded_by: ì—…ë¡œë“œí•œ ìœ ì € ì‹ë³„ì (ê¸°ë³¸ê°’: admin)
        skip_rows: ìŠ¤í‚µí•  í–‰ ìˆ˜ (ê¸°ë³¸ê°’: 2, í—¤ë” ì œì™¸)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # 1. Excel íŒŒì¼ ë¡œë“œ
        logger.info(f"ğŸ“‚ Excel íŒŒì¼ ë¡œë”©: {excel_file}")
        df = pd.read_excel(excel_file, skiprows=skip_rows)

        if 'seller_unique_item_id' not in df.columns:
            logger.error("âŒ 'seller_unique_item_id' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # NaN ì œê±° ë° ì¤‘ë³µ ì œê±°
        unique_item_ids = df['seller_unique_item_id'].dropna().unique()
        logger.info(f"âœ… ê³ ìœ  ìƒí’ˆ ID: {len(unique_item_ids)}ê°œ")

        # 2. DB ì—°ê²°
        connection_string = os.getenv("DATABASE_URL")
        if not connection_string:
            logger.error("âŒ DATABASE_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False

        conn = psycopg2.connect(connection_string)
        cursor = conn.cursor()

        # 3. crawled_productsì—ì„œ unique_item_id ê¸°ì¤€ìœ¼ë¡œ id ì¡°íšŒ
        logger.info(f"ğŸ” crawled_productsì—ì„œ ë§¤ì¹­ ì¡°íšŒ ì¤‘...")

        matched_count = 0
        not_found_count = 0
        already_exists_count = 0
        inserted_count = 0

        for unique_item_id in unique_item_ids:
            unique_item_id_str = str(unique_item_id).strip()
            if not unique_item_id_str:
                continue

            # crawled_productsì—ì„œ ì¡°íšŒ
            cursor.execute("""
                SELECT id FROM crawled_products
                WHERE unique_item_id = %s
                LIMIT 1
            """, (unique_item_id_str,))

            result = cursor.fetchone()

            if result:
                crawled_product_id = result[0]
                matched_count += 1

                # upload_historyì— ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                cursor.execute("""
                    SELECT COUNT(*) FROM upload_history
                    WHERE crawled_product_id = %s AND uploaded_by = %s
                """, (crawled_product_id, uploaded_by))

                if cursor.fetchone()[0] > 0:
                    already_exists_count += 1
                    logger.debug(f"â­ï¸  ì´ë¯¸ ì¡´ì¬: {unique_item_id_str}")
                    continue

                # upload_historyì— INSERT
                cursor.execute("""
                    INSERT INTO upload_history (crawled_product_id, uploaded_by, uploaded_at)
                    VALUES (%s, %s, NOW())
                """, (crawled_product_id, uploaded_by))

                inserted_count += 1

                if inserted_count % 100 == 0:
                    logger.info(f"âœ… ì§„í–‰ì¤‘: {inserted_count}ê°œ ì¶”ê°€...")

            else:
                not_found_count += 1
                logger.debug(f"â“ crawled_productsì— ì—†ìŒ: {unique_item_id_str}")

        # 4. ì»¤ë°‹
        conn.commit()

        # 5. ê²°ê³¼ ì¶œë ¥
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š ì´ì „ ê²°ê³¼:")
        logger.info(f"  Excel ê³ ìœ  ìƒí’ˆ ID: {len(unique_item_ids)}ê°œ")
        logger.info(f"  crawled_products ë§¤ì¹­: {matched_count}ê°œ")
        logger.info(f"  ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì´ë ¥: {already_exists_count}ê°œ")
        logger.info(f"  ì‹ ê·œ ì¶”ê°€: {inserted_count}ê°œ")
        logger.info(f"  ë§¤ì¹­ ì‹¤íŒ¨: {not_found_count}ê°œ")
        logger.info("=" * 60)

        cursor.close()
        conn.close()

        if inserted_count > 0:
            logger.info(f"âœ… upload_historyì— {inserted_count}ê°œ ì´ë ¥ ì¶”ê°€ ì™„ë£Œ")
        else:
            logger.warning("âš ï¸  ì¶”ê°€ëœ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

        return True

    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(
        description="Qoo10_ItemInfo Excel íŒŒì¼ì„ upload_history í…Œì´ë¸”ë¡œ ì´ì „"
    )
    parser.add_argument(
        "--input",
        required=True,
        help="Qoo10_ItemInfo Excel íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument(
        "--user",
        default="admin",
        help="ì—…ë¡œë“œ ìœ ì € ì‹ë³„ì (ê¸°ë³¸ê°’: admin)"
    )
    parser.add_argument(
        "--skip-rows",
        type=int,
        default=2,
        help="ìŠ¤í‚µí•  í–‰ ìˆ˜ (ê¸°ë³¸ê°’: 2)"
    )

    args = parser.parse_args()

    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not Path(args.input).exists():
        logger.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {args.input}")
        sys.exit(1)

    # ì´ì „ ì‹¤í–‰
    success = migrate_to_upload_history(
        excel_file=args.input,
        uploaded_by=args.user,
        skip_rows=args.skip_rows
    )

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()